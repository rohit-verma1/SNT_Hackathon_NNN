{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Downloading required packages for OCR and Summarizing"
      ],
      "metadata": {
        "id": "XxEg2RAUHLQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFGYy6w-NBQC",
        "outputId": "409c1fd9-f8d5-47d9-acc3-8a5a790d90d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.16.3)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Epol_Ty9QZGO",
        "outputId": "2b8c4b93-a5a3-4b5a-d44c-cf1058b6e874"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install tesseract-ocr\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MzcMVTwPMEG",
        "outputId": "83626a51-4e2a-4601-c7b3-ff07ed76491d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2build2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Toch0T2hPzg2",
        "outputId": "db790bc2-85b3-4d2d-b58f-6daf8fa2a048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.30.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CBDmX4UOz3r",
        "outputId": "9e24bede-c1a7-4b65-ead9-4cce45e9da26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "poppler-utils is already the newest version (0.86.1-0ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 38 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Vx1tp3JG_ZI",
        "outputId": "76317de9-4f3c-449c-dd4a-9d325e5209ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.10)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.22.4)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.1)\n"
          ]
        }
      ],
      "source": [
        "pip install PyPDF2 opencv-python pytesseract Pillow\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration"
      ],
      "metadata": {
        "id": "UqLz_otOP_Dp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import PyPDF2\n",
        "import cv2\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from pdf2image import convert_from_path"
      ],
      "metadata": {
        "id": "aTEMOnGsHa-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing a sample handwritten pdf and storing it"
      ],
      "metadata": {
        "id": "gxgFl_EnJ2jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "zlUQW6RiJLTn",
        "outputId": "91a12573-aecc-4ecf-ce7e-662a00ba43da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-afe582b3-b166-46fd-a8ca-e17a7a263a9e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-afe582b3-b166-46fd-a8ca-e17a7a263a9e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using the pretrained t5 model, however to get better results we will have to see if there is a better model suited for our purpose (maybe train one ourselves if we get an appropriate training dataset)"
      ],
      "metadata": {
        "id": "LG2rhYy1SjT3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"t5-base\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6GQ8KosOxUN",
        "outputId": "f3bb7664-b21d-4cf9-fbf2-c79921dad6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py:163: FutureWarning: This tokenizer was incorrectly instantiated with a model max length of 512 which will be corrected in Transformers v5.\n",
            "For now, this behavior is kept to avoid breaking backwards compatibility when padding/encoding with `truncation is True`.\n",
            "- Be aware that you SHOULD NOT rely on t5-base automatically truncating your input to 512 when padding/encoding.\n",
            "- If you want to encode/pad to sequences longer than 512 you can either instantiate this tokenizer with `model_max_length` or pass `max_length` when encoding/padding.\n",
            "- To avoid this warning, please instantiate this tokenizer with `model_max_length` set to your preferred value.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The extract text function (Open to change)"
      ],
      "metadata": {
        "id": "Fnv34KDjODa-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_image(image):\n",
        "    # Convert the image to grayscale\n",
        "    gray_image = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Apply any preprocessing steps (e.g., denoising, thresholding, resizing) using OpenCV if needed\n",
        "\n",
        "    # Noise reduction\n",
        "    denoised_image = cv2.medianBlur(gray_image, 3)\n",
        "\n",
        "    # Skew correction\n",
        "    \"\"\"\n",
        "    coords = np.column_stack(np.where(denoised_image > 0))\n",
        "    angle = cv2.minAreaRect(coords)[-1]\n",
        "    if angle < -45:\n",
        "        angle = -(90 + angle)\n",
        "    else:\n",
        "      angle = -angle\n",
        "    rows, cols = denoised_image.shape\n",
        "    M = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
        "    corrected_image = cv2.warpAffine(denoised_image, M, (cols, rows), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
        "\n",
        "    # Thin line enhancement\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_CROSS, (2, 2))\n",
        "    thinned_image = cv2.erode(denoised_image, kernel, iterations=1)\n",
        "    equalized_image = cv2.equalizeHist(thinned_image)\n",
        "\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    cv2_imshow(image)\n",
        "    cv2_imshow(equalized_image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "    \"\"\"\n",
        "    extracted_text = pytesseract.image_to_string(denoised_image)\n",
        "    print(type(extracted_text))\n",
        "    return extracted_text\n",
        "\n"
      ],
      "metadata": {
        "id": "Vxfu_mWSL1Hl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Summarizes the text passed(parameters and algorithms subject to change)"
      ],
      "metadata": {
        "id": "N6-FA8KgRnrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(text):\n",
        "    inputs = tokenizer.encode(\"summarize: \" + text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
        "    summary_ids = model.generate(inputs, num_beams=6,max_length=500, early_stopping=False)\n",
        "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "    return summary\n"
      ],
      "metadata": {
        "id": "Fhmef8X4Q41m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file = \"/content/1.pdf\"\n",
        "\n",
        "# Read the PDF document\n",
        "summary=\"\"\n",
        "with open(pdf_file, \"rb\") as file:\n",
        "    pdf_reader = PyPDF2.PdfReader(file)\n",
        "    num_pages = len(pdf_reader.pages)\n",
        "\n",
        "    total_extract = \"\"\n",
        "\n",
        "    for page_num in range(num_pages):\n",
        "        page = pdf_reader.pages[page_num]\n",
        "\n",
        "        # Convert PDF page to image\n",
        "        images = convert_from_path(pdf_file, first_page=page_num + 1, last_page=page_num + 1)\n",
        "        image = images[0]\n",
        "\n",
        "        # Perform OCR on the image\n",
        "        extracted_text = extract_text_from_image(image)\n",
        "        summary += generate_summary(extracted_text)\n",
        "        total_extract += extracted_text\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMYN2ttAHfZN",
        "outputId": "4844ae73-5364-4f5f-d012-32dd2b0cd4f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n",
            "<class 'str'>\n",
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(total_extract)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRzgHzXbt3_a",
        "outputId": "83ec16f9-99b0-44ae-f222-63a6f508e790"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\f22 / Who Moved My Cheese? ~~\n",
            "\n",
            "Carlos said, “I guess we resist\n",
            "because we're afraid of change.”\n",
            "\n",
            "“Carlos, you were Captain of the footbal\n",
            "Jessica said. “I never thought I'd hear y\n",
            "anything about being afraid!”\n",
            "\n",
            "They all laughed as they realized that although\n",
            "they had gone off in different directions—fro,,\n",
            "working at home to managing companies—they\n",
            "were experiencing similar feelings.\n",
            "\n",
            "Everyone was trying to cope with the\n",
            "unexpected changes that were happening to them\n",
            "in recent years. And most admitted that they did\n",
            "not know a good way to handle them.\n",
            "\n",
            "Then Michael said, “I used to be afraid of\n",
            "change. When a big change came along in our\n",
            "business, we didn’t know what to do. So we didn't\n",
            "adjust and we almost lost it.\n",
            "\n",
            "“That is,” he continued, “until I heard a funny\n",
            "little story that changed everything.”\n",
            "\n",
            "“How so?” Nathan asked.\n",
            "\n",
            "“Well, the story changed the way | looked at\n",
            "change—from losing something to gaining some\n",
            "thing—and it showed me how to do it. After that,\n",
            "things quickly improved—at work and in my life.\n",
            "\n",
            "“At first | was annoyed with the obvious\n",
            "simplicity of the story because it sounded like\n",
            "something we might have been told 1n school. —\n",
            "ss “Then I realized I was really annoyed with\n",
            "myself for not seeing the obvious and doing what\n",
            "works when things change.\n",
            "\n",
            "Changing\n",
            "\n",
            " \n",
            "\n",
            "team.”\n",
            "ou Say\n",
            "\n",
            "  \n",
            " \n",
            " \n",
            "   \n",
            "  \n",
            "\f \n",
            "\n",
            "Who Moved My Cheese? / 23\n",
            "\n",
            "“When I realized the four characters in the story\n",
            "\n",
            "resented the various parts of myself, I decided\n",
            "who I wanted to act like and I changed.\n",
            "\n",
            "“Later, I passed the story on to some people in\n",
            "our company and they passed it on to others, and\n",
            "soon our business did much better, because most of\n",
            "us adapted to change better. And like me, many\n",
            "people said it helped them in their personal lives.\n",
            "\n",
            "“However there were a few people who said\n",
            "they got nothing out of it. They either knew the\n",
            "lessons and were already living them, or, more\n",
            "commonly, they thought they already knew\n",
            "everything and didn’t want to learn. They couldn’t see\n",
            "why so many others were benefitting from it.\n",
            "\n",
            "“When one of our senior executives, who was\n",
            "having difficulty adapting, said the story was a\n",
            "waste of time, other people kidded him saying\n",
            "they knew which character he was in the story—\n",
            "meaning the one who learned nothing new and did\n",
            "not change.”\n",
            "\n",
            "“What's the story?” Angela asked.\n",
            "\n",
            "“It’s called, Who Moved My Cheese ” i\n",
            "\n",
            "The group laughed. “I think I like 1t already,\n",
            "Carlos said. “Would you tell us the story: Maybe\n",
            "\n",
            "something from it.”\n",
            "E Bee Michsel Ried “I'd be happy to—\n",
            "doesn’t take long.” And so he began:\n",
            "\n",
            " \n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Summary\")\n",
        "print(summary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_ocnqzet15h",
        "outputId": "29a049dc-fc0e-49c7-b2e6-94e1121aa8f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Summary\n",
            "everyone was trying to cope with the unexpected changes that were happening to them in recent years. most admitted that they did not know a good way to handle them. \"i was really annoyed with myself for not seeing the obvious and doing what works when things change.\"\"i realized the four characters in the story resented the various parts of myself,\" he says. many people said it helped them in their personal lives. but a few people said they got nothing out of it.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "u6C_GuYDtu6c"
      }
    }
  ]
}